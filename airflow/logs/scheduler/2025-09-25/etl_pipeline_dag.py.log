[2025-09-25T22:15:56.765+0000] {processor.py:186} INFO - Started process (PID=175) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:15:56.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:15:56.768+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:15:56.768+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:15:56.800+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:15:57.028+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:15:57.027+0000] {override.py:1808} ERROR - Add View Menu Error: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(etl_pipeline) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'etl_pipeline', 'fileloc': '/opt/airflow/dags/etl_pipeline_dag.py', 'fileloc_hash': 65226857745715717, 'data': '{"__version": 1, "dag": {"catchup": false, "fileloc": "/opt/airflow/dags/etl_pipeline_dag.py", "_task_group": {"_group_id": null, "prefix_group_id":  ... (2590 characters truncated) ... null, "bash_command": "python /path/to/dataset_pipeline/scripts/load_to_postgres.py"}, "__type": "operator"}], "dag_dependencies": [], "params": []}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 9, 25, 22, 15, 56, 811255, tzinfo=Timezone('UTC')), 'dag_hash': 'f8dfa9287132f33ee94ab6247cf87a02', 'processor_subdir': '/opt/airflow/dags'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj)
[2025-09-25T22:15:57.033+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:15:57.033+0000] {override.py:1900} INFO - Created Permission View: can edit on None
[2025-09-25T22:15:57.041+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:15:57.040+0000] {override.py:1903} ERROR - Creation of Permission View Error: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "ab_permission_view_permission_id_view_menu_id_uq"
DETAIL:  Key (permission_id, view_menu_id)=(4, 54) already exists.

[SQL: INSERT INTO ab_permission_view (permission_id, view_menu_id) VALUES (%(permission_id)s, %(view_menu_id)s) RETURNING ab_permission_view.id]
[parameters: {'permission_id': 4, 'view_menu_id': 54}]
(Background on this error at: https://sqlalche.me/e/14/gkpj)
[2025-09-25T22:15:57.047+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:15:57.046+0000] {override.py:1900} INFO - Created Permission View: can read on DAG:etl_pipeline
[2025-09-25T22:15:57.054+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:15:57.054+0000] {override.py:1900} INFO - Created Permission View: can delete on DAG Run:etl_pipeline
[2025-09-25T22:15:57.059+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:15:57.059+0000] {override.py:1900} INFO - Created Permission View: menu access on DAG Run:etl_pipeline
[2025-09-25T22:15:57.064+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:15:57.064+0000] {override.py:1900} INFO - Created Permission View: can create on DAG Run:etl_pipeline
[2025-09-25T22:15:57.071+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:15:57.071+0000] {override.py:1903} ERROR - Creation of Permission View Error: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "ab_permission_view_permission_id_view_menu_id_uq"
DETAIL:  Key (permission_id, view_menu_id)=(2, 55) already exists.

[SQL: INSERT INTO ab_permission_view (permission_id, view_menu_id) VALUES (%(permission_id)s, %(view_menu_id)s) RETURNING ab_permission_view.id]
[parameters: {'permission_id': 2, 'view_menu_id': 55}]
(Background on this error at: https://sqlalche.me/e/14/gkpj)
[2025-09-25T22:15:57.071+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:15:57.071+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:15:57.082+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:15:57.082+0000] {dag.py:3262} INFO - Creating ORM DAG for etl_pipeline
[2025-09-25T22:15:57.096+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:15:57.095+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:15:57.109+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:15:57.108+0000] {dagbag.py:698} ERROR - Failed to write serialized DAG: /opt/airflow/dags/etl_pipeline_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "dag_pkey"
DETAIL:  Key (dag_id)=(etl_pipeline) already exists.

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: {'dag_id': 'etl_pipeline', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_parsed_time': datetime.datetime(2025, 9, 25, 22, 15, 57, 94086, tzinfo=Timezone('UTC')), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/etl_pipeline_dag.py', 'processor_subdir': '/opt/airflow/dags', 'owners': 'airflow', 'dag_display_name': None, 'description': None, 'default_view': 'grid', 'schedule_interval': '"@daily"', 'timetable_description': 'At 00:00', 'dataset_expression': 'null', 'max_active_tasks': 16, 'max_active_runs': 16, 'max_consecutive_failed_dag_runs': 0, 'has_task_concurrency_limits': False, 'has_import_errors': False, 'next_dagrun': DateTime(2025, 9, 24, 0, 0, 0, tzinfo=Timezone('UTC')), 'next_dagrun_data_interval_start': DateTime(2025, 9, 24, 0, 0, 0, tzinfo=Timezone('UTC')), 'next_dagrun_data_interval_end': DateTime(2025, 9, 25, 0, 0, 0, tzinfo=Timezone('UTC')), 'next_dagrun_create_after': DateTime(2025, 9, 25, 0, 0, 0, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-09-25T22:15:57.110+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:15:57.110+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:15:57.111+0000] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/api_internal/internal_api_call.py", line 139, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "dag_pkey"
DETAIL:  Key (dag_id)=(etl_pipeline) already exists.

[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, processor_subdir, owners, dag_display_name, description, default_view, schedule_interval, timetable_description, dataset_expression, max_active_tasks, max_active_runs, max_consecutive_failed_dag_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(processor_subdir)s, %(owners)s, %(dag_display_name)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(dataset_expression)s, %(max_active_tasks)s, %(max_active_runs)s, %(max_consecutive_failed_dag_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: {'dag_id': 'etl_pipeline', 'root_dag_id': None, 'is_paused': True, 'is_subdag': False, 'is_active': True, 'last_parsed_time': datetime.datetime(2025, 9, 25, 22, 15, 57, 94086, tzinfo=Timezone('UTC')), 'last_pickled': None, 'last_expired': None, 'scheduler_lock': None, 'pickle_id': None, 'fileloc': '/opt/airflow/dags/etl_pipeline_dag.py', 'processor_subdir': '/opt/airflow/dags', 'owners': 'airflow', 'dag_display_name': None, 'description': None, 'default_view': 'grid', 'schedule_interval': '"@daily"', 'timetable_description': 'At 00:00', 'dataset_expression': 'null', 'max_active_tasks': 16, 'max_active_runs': 16, 'max_consecutive_failed_dag_runs': 0, 'has_task_concurrency_limits': False, 'has_import_errors': False, 'next_dagrun': DateTime(2025, 9, 24, 0, 0, 0, tzinfo=Timezone('UTC')), 'next_dagrun_data_interval_start': DateTime(2025, 9, 24, 0, 0, 0, tzinfo=Timezone('UTC')), 'next_dagrun_data_interval_end': DateTime(2025, 9, 25, 0, 0, 0, tzinfo=Timezone('UTC')), 'next_dagrun_create_after': DateTime(2025, 9, 25, 0, 0, 0, tzinfo=Timezone('UTC'))}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-09-25T22:16:27.941+0000] {processor.py:186} INFO - Started process (PID=185) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:16:27.942+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:16:27.944+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:16:27.943+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:16:27.965+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:16:28.083+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:16:28.083+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:16:28.102+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:16:28.102+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:16:28.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.185 seconds
[2025-09-25T22:16:59.145+0000] {processor.py:186} INFO - Started process (PID=195) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:16:59.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:16:59.149+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:16:59.148+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:16:59.174+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:16:59.202+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:16:59.202+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:16:59.228+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:16:59.228+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:16:59.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.111 seconds
[2025-09-25T22:17:29.738+0000] {processor.py:186} INFO - Started process (PID=205) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:17:29.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:17:29.741+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:17:29.741+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:17:29.762+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:17:29.876+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:17:29.876+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:17:29.896+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:17:29.896+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:17:29.914+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.183 seconds
[2025-09-25T22:18:00.575+0000] {processor.py:186} INFO - Started process (PID=215) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:18:00.576+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:18:00.578+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:18:00.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:18:00.597+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:18:00.622+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:18:00.622+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:18:00.647+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:18:00.647+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:18:00.666+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.098 seconds
[2025-09-25T22:18:31.084+0000] {processor.py:186} INFO - Started process (PID=225) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:18:31.085+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:18:31.088+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:18:31.087+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:18:31.111+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:18:31.226+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:18:31.226+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:18:31.245+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:18:31.245+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:18:31.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.182 seconds
[2025-09-25T22:19:01.695+0000] {processor.py:186} INFO - Started process (PID=235) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:19:01.696+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:19:01.698+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:19:01.698+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:19:01.719+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:19:01.743+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:19:01.743+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:19:01.766+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:19:01.766+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:19:01.783+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.095 seconds
[2025-09-25T22:19:51.598+0000] {processor.py:186} INFO - Started process (PID=175) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:19:51.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:19:51.602+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:19:51.601+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:19:51.625+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:19:51.850+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:19:51.850+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:19:51.870+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:19:51.870+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:19:51.889+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.296 seconds
[2025-09-25T22:20:21.961+0000] {processor.py:186} INFO - Started process (PID=185) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:20:21.962+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:20:21.964+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:20:21.964+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:20:21.986+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:20:22.013+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:20:22.012+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:20:22.039+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:20:22.039+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:20:22.056+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.103 seconds
[2025-09-25T22:20:52.353+0000] {processor.py:186} INFO - Started process (PID=195) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:20:52.354+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:20:52.356+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:20:52.356+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:20:52.377+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:20:52.483+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:20:52.482+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:20:52.500+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:20:52.499+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:20:52.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.172 seconds
[2025-09-25T22:21:22.564+0000] {processor.py:186} INFO - Started process (PID=205) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:21:22.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:21:22.571+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:21:22.570+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:21:22.592+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:21:22.618+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:21:22.618+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:21:22.641+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:21:22.641+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:21:22.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.101 seconds
[2025-09-25T22:21:53.310+0000] {processor.py:186} INFO - Started process (PID=215) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:21:53.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:21:53.313+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:21:53.313+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:21:53.334+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:21:53.439+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:21:53.438+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:21:53.456+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:21:53.456+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:21:53.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.167 seconds
[2025-09-25T22:22:23.913+0000] {processor.py:186} INFO - Started process (PID=225) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:22:23.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:22:23.916+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:22:23.916+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:22:23.936+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:22:23.961+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:22:23.960+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:22:23.983+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:22:23.983+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:22:24.000+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.093 seconds
[2025-09-25T22:22:54.208+0000] {processor.py:186} INFO - Started process (PID=235) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:22:54.209+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:22:54.211+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:22:54.211+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:22:54.234+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:22:54.341+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:22:54.341+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:22:54.360+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:22:54.359+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:22:54.375+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.173 seconds
[2025-09-25T22:23:24.575+0000] {processor.py:186} INFO - Started process (PID=245) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:23:24.576+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:23:24.579+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:23:24.578+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:23:24.599+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:23:24.624+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:23:24.624+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:23:24.652+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:23:24.652+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:23:24.670+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.101 seconds
[2025-09-25T22:23:54.796+0000] {processor.py:186} INFO - Started process (PID=255) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:23:54.797+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:23:54.800+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:23:54.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:23:54.820+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:23:54.926+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:23:54.926+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:23:54.945+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:23:54.945+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:23:54.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.171 seconds
[2025-09-25T22:24:25.267+0000] {processor.py:186} INFO - Started process (PID=265) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:24:25.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:24:25.270+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:24:25.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:24:25.290+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:24:25.314+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:24:25.314+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:24:25.337+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:24:25.337+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:24:25.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.093 seconds
[2025-09-25T22:24:55.785+0000] {processor.py:186} INFO - Started process (PID=275) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:24:55.786+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:24:55.790+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:24:55.789+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:24:55.811+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:24:55.917+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:24:55.917+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:24:55.936+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:24:55.936+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:24:56.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.339 seconds
[2025-09-25T22:25:26.517+0000] {processor.py:186} INFO - Started process (PID=285) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:25:26.518+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:25:26.521+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:25:26.520+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:25:26.543+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:25:26.568+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:25:26.568+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:25:26.592+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:25:26.592+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:25:26.610+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.099 seconds
[2025-09-25T22:25:57.512+0000] {processor.py:186} INFO - Started process (PID=295) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:25:57.513+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:25:57.516+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:25:57.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:25:57.537+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:25:57.648+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:25:57.648+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:25:57.820+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:25:57.820+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:25:57.836+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.330 seconds
[2025-09-25T22:26:28.373+0000] {processor.py:186} INFO - Started process (PID=305) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:26:28.374+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:26:28.377+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:26:28.376+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:26:28.398+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:26:28.423+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:26:28.423+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:26:28.447+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:26:28.447+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:26:28.463+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.096 seconds
[2025-09-25T22:26:59.119+0000] {processor.py:186} INFO - Started process (PID=315) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:26:59.120+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:26:59.122+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:26:59.122+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:26:59.145+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:26:59.256+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:26:59.256+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:26:59.275+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:26:59.275+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:26:59.292+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.180 seconds
[2025-09-25T22:27:30.116+0000] {processor.py:186} INFO - Started process (PID=325) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:27:30.117+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:27:30.119+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:27:30.119+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:27:30.140+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:27:30.164+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:27:30.164+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:27:30.188+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:27:30.187+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:27:30.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.094 seconds
[2025-09-25T22:28:00.425+0000] {processor.py:186} INFO - Started process (PID=335) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:28:00.426+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:28:00.429+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:28:00.429+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:28:00.451+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:28:00.564+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:28:00.563+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:28:00.585+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:28:00.584+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:28:00.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.348 seconds
[2025-09-25T22:28:31.318+0000] {processor.py:186} INFO - Started process (PID=345) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:28:31.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:28:31.323+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:28:31.322+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:28:31.345+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:28:31.373+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:28:31.372+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:28:31.399+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:28:31.398+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:28:31.418+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.106 seconds
[2025-09-25T22:29:02.180+0000] {processor.py:186} INFO - Started process (PID=355) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:29:02.181+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:29:02.185+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:29:02.184+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:29:02.224+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:29:02.443+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:29:02.443+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:29:02.464+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:29:02.464+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:29:02.481+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.318 seconds
[2025-09-25T22:29:32.946+0000] {processor.py:186} INFO - Started process (PID=365) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:29:32.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:29:32.953+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:29:32.952+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:29:32.975+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:29:33.007+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:29:33.007+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:29:33.033+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:29:33.033+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:29:33.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.114 seconds
[2025-09-25T22:30:03.659+0000] {processor.py:186} INFO - Started process (PID=375) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:30:03.660+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:30:03.662+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:30:03.662+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:30:03.681+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:30:03.783+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:30:03.783+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:30:03.801+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:30:03.801+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:30:03.817+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.163 seconds
[2025-09-25T22:30:34.095+0000] {processor.py:186} INFO - Started process (PID=385) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:30:34.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:30:34.098+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:30:34.097+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:30:34.116+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:30:34.142+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:30:34.142+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:30:34.169+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:30:34.169+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:30:34.186+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.096 seconds
[2025-09-25T22:31:04.570+0000] {processor.py:186} INFO - Started process (PID=395) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:31:04.571+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:31:04.573+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:31:04.573+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:31:04.593+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:31:04.693+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:31:04.693+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:31:04.862+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:31:04.861+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:31:04.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.314 seconds
[2025-09-25T22:31:34.971+0000] {processor.py:186} INFO - Started process (PID=405) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:31:34.972+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:31:34.974+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:31:34.974+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:31:34.994+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:31:35.018+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:31:35.017+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:31:35.041+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:31:35.040+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:31:35.058+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.092 seconds
[2025-09-25T22:32:05.783+0000] {processor.py:186} INFO - Started process (PID=415) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:32:05.784+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:32:05.786+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:32:05.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:32:05.804+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:32:05.909+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:32:05.909+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:32:05.927+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:32:05.927+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:32:05.944+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.166 seconds
[2025-09-25T22:32:36.466+0000] {processor.py:186} INFO - Started process (PID=425) to work on /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:32:36.467+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/etl_pipeline_dag.py for tasks to queue
[2025-09-25T22:32:36.468+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:32:36.468+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:32:36.487+0000] {processor.py:925} INFO - DAG(s) 'etl_pipeline' retrieved from /opt/airflow/dags/etl_pipeline_dag.py
[2025-09-25T22:32:36.514+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:32:36.514+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-09-25T22:32:36.538+0000] {logging_mixin.py:190} INFO - [2025-09-25T22:32:36.538+0000] {dag.py:4180} INFO - Setting next_dagrun for etl_pipeline to 2025-09-24 00:00:00+00:00, run_after=2025-09-25 00:00:00+00:00
[2025-09-25T22:32:36.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/etl_pipeline_dag.py took 0.094 seconds
